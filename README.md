# ChatBotAI
This AI chatbot uses LangChain, Flask, and Ollama for real-time word-by-word responses. It features a professional UI, resizable chat, and aligned message bubbles. Runs offline with Mistral or Llama 3 for fast, private AI interactions. ğŸš€
Here's a **README.md** file with all the necessary steps to set up and run your chatbot project. It includes:  

- Project overview  
- Features  
- Prerequisites  
- Installation steps  
- How to run the chatbot  
- Example usage  
- Future improvements  

---

## **ğŸ“ README.md**
```md
# AI Chatbot with Streaming Responses & Professional UI

This is a **fully functional AI chatbot** built using **LangChain, Flask, and Ollama**. It supports **real-time word-by-word streaming responses**, customizable UI, and smooth user interaction.

## ğŸš€ Features
âœ… **Real-time streaming responses** (word-by-word)  
âœ… **User messages right-aligned & bot responses left-aligned**  
âœ… **Separate message bubbles** for clean UI  
âœ… **Resizable chatbox** (drag to adjust size)  
âœ… **Auto-scroll to latest message**  
âœ… **Proper text formatting in bot responses**  
âœ… **Lightweight and runs locally**  

---

## ğŸ“Œ Prerequisites

### ğŸ›  **Install Ollama & Choose an LLM**
To run this chatbot, **install Ollama** and pull either **Mistral** or **Llama 3** based on your choice.

ğŸ”¹ **Install Ollama** (if not already installed)  
- **Windows**: Download from [Ollama's website](https://ollama.com/download)  
- **Mac/Linux**: Run:
  ```sh
  curl -fsSL https://ollama.com/install.sh | sh
  ```

ğŸ”¹ **Download a Language Model (LLM)**  
Choose **either** of the two models:

1ï¸âƒ£ **Mistral (Smaller & Faster)**  
   ```sh
   ollama pull mistral
   ```

2ï¸âƒ£ **Llama 3 (More Powerful but Heavier)**  
   ```sh
   ollama pull llama3
   ```

---

## ğŸ“¥ Installation
Clone this repository and install dependencies:

```sh
git clone https://github.com/yourusername/chatbot-ui-ollama.git
cd chatbot-ui-ollama
pip install flask
```

---

## ğŸƒ Running the Chatbot

### 1ï¸âƒ£ **Start Ollama Service**
```sh
ollama serve
```

### 2ï¸âƒ£ **Run the Flask Backend**
```sh
python app.py
```

### 3ï¸âƒ£ **Open in Browser**
Go to:  
ğŸ”— [http://127.0.0.1:5000](http://127.0.0.1:5000)

---

## ğŸ’¬ Example Usage
1ï¸âƒ£ Type a question (e.g., *"What is Python?"*)  
2ï¸âƒ£ The chatbot **starts responding immediately** (word-by-word)  
3ï¸âƒ£ Messages appear in **separate bubbles** with **proper formatting**  

---

## ğŸ”§ Future Improvements
- ğŸ”„ **Memory Handling** (Remember past messages)  
- ğŸ¨ **More UI Customization**  
- ğŸŒ **Deploy on Cloud (AWS/GCP)**  

---

### â­ Star & Fork this Repo!  
If you like this project, feel free to **star â­** it and **contribute**! ğŸš€  
```

---

### **âœ… Next Steps**
- **Upload this README.md** to your **GitHub repo**  
- **Make sure all code is working** before pushing ğŸš€  
- **Share your GitHub repo link** if you need improvements! ğŸ˜Š
